{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Net2Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/cvai-roig-lab/Net2Brain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Evaluation\n",
    "\n",
    "In this tutorial notebook, we'll showcase how to leverage the evaluation capabilities of Net2Brain and visualize the resulting data. You can choose from three evaluation metrics:\n",
    "\n",
    "1. \"RSA\"\n",
    "2. \"Weighted RSA\"\n",
    "3. \"Searchlight\"\n",
    "\n",
    "Each module generates a pandas DataFrame, which can be seamlessly integrated with the toolbox's built-in plotting functionality."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representational Similiratiy Analysis (RSA) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net2brain.evaluations.rsa import RSA\n",
    "from net2brain.utils.download_datasets import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_path, roi_path = load_dataset(\"bonner_pnas2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rdms = \"AlexNet_RDM\" \n",
    "brain_rdms = roi_path\n",
    "\n",
    "# Start RSA\n",
    "evaluation_alexnet = RSA(model_rdms, brain_rdms, model_name=\"AlexNet\")\n",
    "\n",
    "# Evaluation - Returns a pandas dataframe\n",
    "dataframe1 = evaluation_alexnet.evaluate() \n",
    "\n",
    "# Show results\n",
    "display(dataframe1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing RSA Evaluation Results\n",
    "\n",
    "The integrated plotting functionality of the toolbox allows you to easily visualize evaluation results. To achieve this, initialize the class with a list of DataFrames obtained from the evaluation. Make sure that each DataFrame:\n",
    "\n",
    "1. Contains the same ROIs, signifying that each test was performed on the same brain RDMs.\n",
    "2. Has a distinct model name, which can be set manually or through the \"model_name\" parameter during evaluation (as mentioned earlier).\n",
    "\n",
    "Here's an example of how to plot the data using a single DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net2brain.evaluations.plotting import Plotting\n",
    "\n",
    "plotter = Plotting([dataframe1])\n",
    "results_dataframe = plotter.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose between `metric=\"R2\"` (default) or `metric=\"R\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = plotter.plot(metric=\"R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also choose between plotting the best layers or `plot_all_layers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = plotter.plot_all_layers(metric=\"R2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing RSA Evaluation Results - Multiple models\n",
    "\n",
    "As previously mentioned, you can also plot multiple models in a single plot. To do this, simply include additional DataFrames in the list:\n",
    "\n",
    "        Plotting([dataframe1, dataframe2, dataframe3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start RSA for AlexNet\n",
    "evaluation_alexnet = RSA(\"AlexNet_RDM\", brain_rdms, save_path=\"./\", model_name=\"AlexNet\")\n",
    "dataframe2 = evaluation_alexnet.evaluate() \n",
    "\n",
    "# Start RSA for ResNet50\n",
    "evaluation_resnet = RSA(\"ResNet50_RDM\", brain_rdms, save_path=\"./\", model_name=\"ResNet50\")\n",
    "dataframe1 = evaluation_resnet.evaluate() \n",
    "\n",
    "\n",
    "plotter = Plotting([dataframe1,dataframe2])\n",
    "results_dataframe = plotter.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing RSA Evaluation Results - Multiple models with significance\n",
    "\n",
    "\n",
    "Furthermore, you might be interested in determining whether one model is significantly better than another, and not merely due to random variation. In this case, you can utilize the `compare_model` functionality provided by the toolbox. Use the following syntax:\n",
    "\n",
    "        ttest, sig_pairs = eval_1.compare_model(eval_2)\n",
    "\n",
    "If you wish to display the significance as well, use the parameter pairs=[]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing statistical significance\n",
    "ttest, sig_pairs = evaluation_alexnet.compare_model(evaluation_resnet)\n",
    "print(sig_pairs)\n",
    "\n",
    "# Plotting with significance\n",
    "plotter = Plotting([dataframe1,dataframe2])\n",
    "results_dataframe = plotter.plot(pairs=sig_pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRSA Evaluation\n",
    "In addition to the standard RSA, Net2Brain also supports weighted RSA (WRSA) as an evaluation metric. WRSA allows for the incorporation of weights into the analysis, providing an alternative approach to evaluating model performance and examining the relationship between neural representations and computational models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net2brain.evaluations.weighted_rsa import WRSA\n",
    "\n",
    "# Start RSA\n",
    "evaluation = WRSA(model_rdms, brain_rdms, save_path=\"./\", model_name=\"ResNet50\")\n",
    "\n",
    "# Evaluation - Returns a pandas dataframe\n",
    "dataframe1 = evaluation.evaluate() \n",
    "\n",
    "display(dataframe1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searchlight\n",
    "The toolbox offers the capability to perform searchlight analysis using Searchlight RDMs in the [ROI, subject, stimuli, stimuli] format. Please note that this toolbox does not include RDMs for testing purposes. However, if you have access to RDMs, you are welcome to use this functionality to conduct searchlight analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net2brain.evaluations.searchlight import Searchlight\n",
    "model_rdms = \"-\"\n",
    "searchlight_rdm = \"-\"\n",
    "\n",
    "evaluation = Searchlight(model_rdms, searchlight_rdm, save_path=\"./\")\n",
    "evaluation.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "N2B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2143370df03d7e8d8afb3cb32a8181ea228f5a6f13a304f592978240ae0036e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
