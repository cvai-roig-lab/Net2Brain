{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Net2Brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"workshops/data/Net2Brain_Logo.png\" width=\"25%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U git+https://github.com/cvai-roig-lab/Net2Brain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Evaluation\n",
    "\n",
    "In this tutorial notebook, we'll showcase how to leverage the evaluation capabilities of Net2Brain and visualize the resulting data. You can choose from three evaluation metrics:\n",
    "\n",
    "1. \"RSA\"\n",
    "2. \"Weighted RSA\"\n",
    "3. \"Searchlight\"\n",
    "\n",
    "Each module generates a pandas DataFrame, which can be seamlessly integrated with the toolbox's built-in plotting functionality."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representational Similiratiy Analysis (RSA) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net2brain.evaluations.rsa import RSA\n",
    "from net2brain.utils.download_datasets import DatasetBonnerPNAS2017\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_bonner = DatasetBonnerPNAS2017.load_dataset()\n",
    "stimuli_path = paths_bonner[\"stimuli_path\"]\n",
    "roi_path = paths_bonner[\"roi_path\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rdms = \"AlexNet_RDM\" \n",
    "brain_rdms = roi_path\n",
    "\n",
    "# Start RSA\n",
    "evaluation_alexnet = RSA(model_rdms, brain_rdms, model_name=\"AlexNet\")\n",
    "\n",
    "# Evaluation - Returns a pandas dataframe\n",
    "dataframe1 = evaluation_alexnet.evaluate() \n",
    "\n",
    "# Show results\n",
    "display(dataframe1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSA class can also take an optional argument `layer_skips` to skip certain layers during evaluation. This can be\n",
    "useful when you have a large number of layers extracted and want to test only a subset of them.\n",
    "\n",
    "Also, by default the evaluation returns the squared correlations. If you don't want to square the correlations, you\n",
    "can set `squared=False`. This is different from later changing the metric in plotting, as correlations are\n",
    "subject-averaged by then, and also negative correlations cannot be recovered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing RSA Evaluation Results\n",
    "\n",
    "The integrated plotting functionality of the toolbox allows you to easily visualize evaluation results. To achieve this, initialize the class with a list of DataFrames obtained from the evaluation. Make sure that each DataFrame:\n",
    "\n",
    "1. Contains the same ROIs, signifying that each test was performed on the same brain RDMs.\n",
    "2. Has a distinct model name, which can be set manually or through the \"model_name\" parameter during evaluation (as mentioned earlier).\n",
    "\n",
    "Here's an example of how to plot the data using a single DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net2brain.evaluations.plotting import Plotting\n",
    "\n",
    "plotter = Plotting([dataframe1])\n",
    "results_dataframe = plotter.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose between `metric=\"R2\"` (default) or `metric=\"R\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = plotter.plot(metric=\"R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also choose between plotting the best layers or `plot_all_layers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = plotter.plot_all_layers(metric=\"R2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing RSA Evaluation Results - Multiple models\n",
    "\n",
    "As previously mentioned, you can also plot multiple models in a single plot. To do this, simply include additional DataFrames in the list:\n",
    "\n",
    "        Plotting([dataframe1, dataframe2, dataframe3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start RSA for AlexNet\n",
    "evaluation_alexnet = RSA(\"AlexNet_RDM\", brain_rdms, save_path=\"./\", model_name=\"AlexNet\")\n",
    "dataframe2 = evaluation_alexnet.evaluate() \n",
    "\n",
    "# Start RSA for ResNet50\n",
    "evaluation_resnet = RSA(\"ResNet50_RDM\", brain_rdms, save_path=\"./\", model_name=\"ResNet50\")\n",
    "dataframe1 = evaluation_resnet.evaluate() \n",
    "\n",
    "\n",
    "plotter = Plotting([dataframe1,dataframe2])\n",
    "results_dataframe = plotter.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing RSA Evaluation Results - Multiple models with significance\n",
    "\n",
    "\n",
    "Furthermore, you might be interested in determining whether one model is significantly better than another, and not merely due to random variation. In this case, you can utilize the `compare_model` functionality provided by the toolbox. Use the following syntax:\n",
    "\n",
    "        ttest, sig_pairs = eval_1.compare_model(eval_2)\n",
    "\n",
    "If you wish to display the significance as well, use the parameter pairs=[]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing statistical significance\n",
    "ttest, sig_pairs = evaluation_alexnet.compare_model(evaluation_resnet)\n",
    "print(sig_pairs)\n",
    "\n",
    "# Plotting with significance\n",
    "plotter = Plotting([dataframe1,dataframe2])\n",
    "results_dataframe = plotter.plot(pairs=sig_pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRSA Evaluation\n",
    "In addition to the standard RSA, Net2Brain also supports weighted RSA (WRSA) as an evaluation metric. WRSA allows for the incorporation of weights into the analysis, providing an alternative approach to evaluating model performance and examining the relationship between neural representations and computational models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net2brain.evaluations.weighted_rsa import WRSA\n",
    "\n",
    "# Start RSA\n",
    "evaluation = WRSA(model_rdms, brain_rdms, save_path=\"./\", model_name=\"ResNet50\")\n",
    "\n",
    "# Evaluation - Returns a pandas dataframe\n",
    "dataframe1 = evaluation.evaluate() \n",
    "\n",
    "display(dataframe1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searchlight\n",
    "The toolbox offers the capability to perform searchlight analysis using Searchlight RDMs in the [ROI, subject, stimuli, stimuli] format. Please note that this toolbox does not include RDMs for testing purposes. However, if you have access to RDMs, you are welcome to use this functionality to conduct searchlight analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net2brain.evaluations.searchlight import Searchlight\n",
    "model_rdms = \"-\"\n",
    "searchlight_rdm = \"-\"\n",
    "\n",
    "evaluation = Searchlight(model_rdms, searchlight_rdm, save_path=\"./\")\n",
    "evaluation.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Encoding and Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The toolbox offers `Linear Encoding` and `Ridge Regression` as evaluation metrics. These methods use raw features, without converting them into Representational Dissimilarity Matrices (RDMs), to train an encoding model that predicts unseen brain data.\n",
    "\n",
    "* **Linear Encoding** uses Principal Component Analysis (PCA) followed by Linear Regression to reduce the feature dimensionality and then predict brain activity. It helps understand which features from the model correlate with brain responses.\n",
    "\n",
    "* **Ridge Regression** extends linear encoding by adding regularization, which prevents overfitting and helps dealing with noise which may be part of the neural data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Encoding` Function Parameters:\n",
    "\n",
    "- **feat_path (str)**: Path to the directory with model activation `.npz` files for multiple layers.\n",
    "- **roi_path (str or list)**: Path to the directory containing .npy fMRI data files for multiple ROIs.\n",
    "If we have a list of folders, each folder will be searched for .npy files and the analysis will be run for each. If \n",
    "folders contain different subject ROIs, make sure that the .npy file names are unique (e.g. V1_subj1.npy) across the \n",
    "folders.\n",
    "- **model_name (str)**: Name of the model (used for labeling in output files).\n",
    "- **trn_tst_split (int or float)**: Data to use for training (rest is used for testing). If int, it is absolute \n",
    "number of samples, if float, it is a fraction of the whole dataset (e.g., 0.8 means 80% training, 20% testing).\n",
    "- **n_folds (int)**: Number of cross-validation folds.\n",
    "- **n_components (int)**: Number of principal components to retain during PCA (only linear encoding)\n",
    "- **batch_size (int)**: Batch size for Incremental PCA. (only linear encoding)\n",
    "- **srp_before_pca (bool)**: Whether to apply Sparse Random Projection (SRP) before PCA. Use when features are so\n",
    "high-dimensional that IncrementalPCA runs out of memory after some batches. Num of dims estimated by SRP. (only linear encoding)\n",
    "- **srp_on_subset (int or None)**: Number of samples to use for SRP fitting. If None, all samples are used,\n",
    "which is recommended if you have enough memory (if `srp_before_pca` is False it has no effect). (only linear encoding)\n",
    "- **mem_mode (str)**: 'saver' or 'performance'; Choose 'saver' if you don't have enough memory to store all\n",
    "training sample features, otherwise leave 'performance' as default. If you have `srp_before_pca` enabled,\n",
    "in the first case you will also need to restrict the number of samples for SRP fitting with `srp_on_subset`. (only linear encoding)\n",
    "- **avg_across_feat (bool)**: If True, averages activations across axis 1 to handle varying feature sizes (with LLMs for example).\n",
    "- **return_correlations (bool)**: If True, return correlation values for each voxel (only with veRSA False).\n",
    "- **random_state (int)**: Seed for reproducibility of results.\n",
    "- **shuffle (bool)**: Whether to shuffle the data before splitting into training and testing sets.\n",
    "- **save_path (str)**: Directory to save results (`Linear_Encoding_Results` by default).\n",
    "- **file_name (str or None)**: Custom file name for saved results.\n",
    "- **average_across_layers (bool)**: If True, averages correlation values across layers before saving the results.\n",
    "- **veRSA (bool)**: If True, performs RSA on top of the voxelwise encoding.\n",
    "- **save_model (bool)**: Save the linear regression model to disk.\n",
    "- **save_pca (bool)**: Save the PCA transform to disk.\n",
    "- **layer_skips (tuple, optional)**: Names of the model layers to skip during encoding. Use original layer names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For a proper tutorial check out \"notebooks/Workshops/Cognition Academy Dresden Notebook 2.ipynb\"\n",
    "\n",
    "from net2brain.evaluations.encoding import Linear_Encoding, Ridge_Encoding\n",
    "\n",
    "Linear_Encoding(feat_path=\"feat_path\",  # Or use Ridge Encoding\n",
    "                roi_path=\"roi_path\",\n",
    "                model_name=\"model_name\",\n",
    "                save_path=\"save_path\",\n",
    "                file_name=\"file_name\",\n",
    "                avg_across_feat=True,\n",
    "                return_correlations=False,\n",
    "                average_across_layers=False)\n",
    "\n",
    "\n",
    "Ridge_Encoding(feat_path=\"feat_path\", \n",
    "                roi_path=\"roi_path\",\n",
    "                model_name=\"model_name\",\n",
    "                save_path=\"save_path\",\n",
    "                file_name=\"file_name\",\n",
    "                avg_across_feat=True,\n",
    "                return_correlations=False,\n",
    "                average_across_layers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a proper tutorial check out \"notebooks/Workshops/Cognition Academy Dresden Notebook 2.ipynb\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Centered Kernel Alignment (CKA) Evaluation**\n",
    "\n",
    "Centered Kernel Alignment (CKA) measures the similarity between two datasets, such as neural representations and brain activity, based on pairwise similarities within each dataset. It is scale-invariant and focuses on relationships rather than raw data.\n",
    "\n",
    "#### **CKA Function Parameters**\n",
    "\n",
    "- **`feat_path` (str):** Path to the directory containing `.npz` files with model activations for multiple layers. Each file should be organized by layer names.\n",
    "- **`brain_path` (str):** Path to the directory containing `.npy` files with fMRI data for different ROIs. \n",
    "- **`model_name` (str):** Name of the model, used for labeling in the output.\n",
    "\n",
    "#### **Input Format**\n",
    "\n",
    "1. **Model Activations (`feat_path`):** Each `.npz` file corresponds to one stimulus and contains a dictionary of layer activations, just like the Feature Extractor prepares the files.\n",
    "   - Example:\n",
    "     ```python\n",
    "     {\n",
    "       'layer1': np.array([...]),  # Shape: (1, 64, 56, 56)\n",
    "       'layer2': np.array([...]),  # Shape: (1, 128, 28, 28)\n",
    "       ...\n",
    "     }\n",
    "     ```\n",
    "2. **Brain Data (`brain_path`):** Each `.npy` file contains fMRI responses for an ROI, shaped as `(n_stimuli, n_voxels)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from net2brain.evaluations.cka import CKA\n",
    "\n",
    "# Define paths for dummy feature and brain data\n",
    "feat_path = \"dummy_feat_path\"\n",
    "brain_path = \"dummy_brain_path\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(feat_path, exist_ok=True)\n",
    "os.makedirs(brain_path, exist_ok=True)\n",
    "\n",
    "# Number of stimuli and voxels\n",
    "n_stimuli = 100\n",
    "n_voxels = 10\n",
    "\n",
    "# Generate dummy fMRI data\n",
    "np.save(f\"{brain_path}/roi1.npy\", np.random.rand(n_stimuli, n_voxels))  # Shape: (10 stimuli, 1000 voxels)\n",
    "\n",
    "# Generate dummy feature data for each stimulus\n",
    "for i in range(n_stimuli):\n",
    "    np.savez_compressed(f\"{feat_path}/stimulus_{i+1}.npz\",\n",
    "                        layer1=np.random.rand(20),  # Example layer\n",
    "                        layer2=np.random.rand(20))  # Example layer\n",
    "\n",
    "# Run the CKA evaluation\n",
    "results = CKA.run(feat_path=feat_path, brain_path=brain_path, model_name=\"clip_vit_b32\")\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, with raw data you can also call the computation directly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from net2brain.evaluations.cka import CKA\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "np.random.seed(45)\n",
    "\n",
    "# Generate dummy data\n",
    "n_samples = 100                 # Number of samples (e.g., stimuli)\n",
    "n_features_per_layer = 20       # Number of features in the DNN layer\n",
    "n_voxels = 10                   # Number of fMRI response voxels\n",
    "\n",
    "# Randomly generate DNN activations and fMRI responses\n",
    "layer1_activations = np.random.rand(n_samples, n_features_per_layer)\n",
    "fMRI_activations = np.random.rand(n_samples, n_voxels)\n",
    "\n",
    "# Instantiate the CKA object\n",
    "cka = CKA()\n",
    "\n",
    "# Compute the linear CKA score between DNN activations and fMRI responses\n",
    "cka_score = cka.linear_CKA(layer1_activations, fMRI_activations)\n",
    "\n",
    "# Print the resulting CKA score\n",
    "print(\"Linear CKA Score:\", cka_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Distributional Comparison (DC) Evaluation**\n",
    "\n",
    "Distributional Comparison evaluates the similarity between two datasets by comparing the distributions of their features. Two metrics are available:\n",
    "- **Jensen-Shannon Divergence (JSD):** Measures the divergence between two probability distributions. It is symmetric and always bounded between 0 and 1.\n",
    "- **Wasserstein Distance (WD):** Also known as Earth Mover's Distance, measures the cost of transforming one distribution into the other.\n",
    "\n",
    "Use `metric=\"jsd\"` for bounded divergence measures or `metric=\"wasserstein\"` for more general comparisons.\n",
    "\n",
    "\n",
    "#### **DC Function Parameters**\n",
    "\n",
    "- **`feat_path` (str):** Path to the directory containing `.npz` files with model activations for multiple layers.\n",
    "- **`brain_path` (str):** Path to the directory containing `.npy` files with fMRI data for different ROIs.\n",
    "- **`metric` (str):** Metric to compare distributions ('jsd' or 'wasserstein').\n",
    "- **`bins` (int):**  Number of bins for histogramming.\n",
    "- **`model_name` (str):** Name of the model, used for labeling in the output.\n",
    "\n",
    "#### **Input Format**\n",
    "\n",
    "1. **Model Activations (`feat_path`):** Each `.npz` file corresponds to one stimulus and contains a dictionary of layer activations, just like the Feature Extractor prepares the files.\n",
    "   - Example:\n",
    "     ```python\n",
    "     {\n",
    "       'layer1': np.array([...]),  # Shape: (1, 64, 56, 56)\n",
    "       'layer2': np.array([...]),  # Shape: (1, 128, 28, 28)\n",
    "       ...\n",
    "     }\n",
    "     ```\n",
    "2. **Brain Data (`brain_path`):** Each `.npy` file contains fMRI responses for an ROI, shaped as `(n_stimuli, n_voxels)`.\n",
    "\n",
    "#### **Warning**\n",
    "\n",
    "If the feature lengths of `feat_path` and `brain_path` differ, **PCA** is applied to reduce them to the same dimensionality. This step ensures compatibility but alters the feature space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from net2brain.evaluations.distributional_comparisons import DistributionalComparison\n",
    "\n",
    "\n",
    "# Define paths for dummy feature and brain data\n",
    "feat_path = \"dummy_feat_path\"\n",
    "brain_path = \"dummy_brain_path\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(feat_path, exist_ok=True)\n",
    "os.makedirs(brain_path, exist_ok=True)\n",
    "\n",
    "# Number of stimuli and voxels\n",
    "n_stimuli = 100\n",
    "n_voxels = 10\n",
    "\n",
    "# Generate dummy fMRI data\n",
    "np.save(f\"{brain_path}/roi1.npy\", np.random.rand(n_stimuli, n_voxels))  # Shape: (10 stimuli, 1000 voxels)\n",
    "\n",
    "# Generate dummy feature data for each stimulus\n",
    "for i in range(n_stimuli):\n",
    "    np.savez_compressed(f\"{feat_path}/stimulus_{i+1}.npz\",\n",
    "                        layer1=np.random.rand(20),  # Example layer\n",
    "                        layer2=np.random.rand(20))  # Example layer\n",
    "\n",
    "# Running Distributional Comparison (JSD)\n",
    "results_jsd = DistributionalComparison.run(feat_path=\"dummy_feat_path\", \n",
    "                                           brain_path=\"dummy_brain_path\", \n",
    "                                           metric=\"jsd\", \n",
    "                                           bins=50,\n",
    "                                           model_name=\"clip_vit_b32\")\n",
    "print(\"Results (JSD):\")\n",
    "display(results_jsd)\n",
    "\n",
    "# Running Distributional Comparison (Wasserstein)\n",
    "results_wasserstein = DistributionalComparison.run(feat_path=\"dummy_feat_path\", \n",
    "                                                   brain_path=\"dummy_brain_path\", \n",
    "                                                   metric=\"wasserstein\", \n",
    "                                                   bins=50,\n",
    "                                                   model_name=\"clip_vit_b32\")\n",
    "print(\"Results (Wasserstein):\")\n",
    "display(results_wasserstein)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, with raw data you can also call the computation directly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from net2brain.evaluations.distributional_comparisons import DistributionalComparison\n",
    "\n",
    "# Set a fixed random seed for reproducibility\n",
    "np.random.seed(45)\n",
    "\n",
    "# Generate dummy data\n",
    "n_samples = 100                 # Number of samples (e.g., stimuli)\n",
    "n_features_per_layer = 20       # Number of features in the DNN layer\n",
    "n_voxels = 20                   # Number of fMRI response voxels\n",
    "\n",
    "# Randomly generate DNN activations and fMRI responses\n",
    "layer1_activations = np.random.rand(n_samples, n_features_per_layer)\n",
    "fMRI_activations = np.random.rand(n_samples, n_voxels)\n",
    "\n",
    "# Instantiate the DC object\n",
    "dc = DistributionalComparison()\n",
    "\n",
    "# Compute the linear DC score between DNN activations and fMRI responses\n",
    "dc_score = dc.compare_distributions(layer1_activations, fMRI_activations, metric=\"jsd\")\n",
    "\n",
    "# Print the resulting CKA score\n",
    "print(\"DC Score:\", dc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Encoding and Structured Variance Partitioning\n",
    "\n",
    "## Stacked Encoding\n",
    "\n",
    "Stacked encoding combines predictions from multiple feature spaces (like different neural network layers) to better predict brain activity. Instead of using just one layer or simply concatenating layers, stacked encoding:\n",
    "\n",
    "### How Stacked Encoding Works:\n",
    "\n",
    "1. **First-level models:** Train separate ridge regression models for each feature space (e.g., each layer of a neural network)\n",
    "2. **Second-level combination:** Learn a convex combination of these individual predictions to create a final prediction\n",
    "\n",
    "The weights of this combination indicate the importance of each feature space\n",
    "These weights must be positive and sum to 1, ensuring interpretability\n",
    "\n",
    "\n",
    "## Structured Variance Partitioning\n",
    "\n",
    "Structured variance partitioning identifies which layers of a neural network are most important for predicting activity in different brain regions:\n",
    "\n",
    "- **Forward direction**: Starts simple and adds complexity  \n",
    "  - Identifies how complex representations need to be for prediction  \n",
    "\n",
    "- **Backward direction**: Starts complex and adds simpler layers  \n",
    "  - Determines if brain regions also process lower-level information  \n",
    "\n",
    "Together, these analyses create an *interval* of relevant layers for each brain region. The `Stacked_Variance_Partitioning` function performs this analysis using R-Correlation values from stacked encoding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Generate Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define parameters\n",
    "N_sample = 1000  # Images\n",
    "dim_X1 = 50  # Feature Dim 1\n",
    "dim_X2 = 100  # Feature Dim 2\n",
    "dim_X3 = 25  # Feature Dim 3\n",
    "dim_Y = 10  # Amount Voxels\n",
    "\n",
    "# Generate random feature data\n",
    "X1 = np.random.randn(N_sample, dim_X1)\n",
    "X2 = np.random.randn(N_sample, dim_X2)\n",
    "X3 = np.random.randn(N_sample, dim_X3)\n",
    "\n",
    "# Generate brain data\n",
    "Y = 0.3 * X1.dot(np.random.randn(dim_X1, dim_Y)) + \\\n",
    "   0.3 * X2.dot(np.random.randn(dim_X2, dim_Y)) + \\\n",
    "   0.4 * X3.dot(np.random.randn(dim_X3, dim_Y))\n",
    "\n",
    "# Define output directory\n",
    "output_dir = \"stacked_encoding_sample_data/features\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(\"sample_data\", exist_ok=True)\n",
    "\n",
    "# Save each sample into a separate .npz file\n",
    "for i in range(N_sample):\n",
    "   file_path = os.path.join(output_dir, f\"sample_{i+1:04d}.npz\")\n",
    "   np.savez(file_path, X1=X1[i], X2=X2[i], X3=X3[i])\n",
    "\n",
    "# Save Y data as a single .npy file\n",
    "y_file_path = \"stacked_encoding_sample_data/brain_data.npy\"\n",
    "np.save(y_file_path, Y)\n",
    "\n",
    "print(f\"Data saved to {output_dir} with {N_sample} .npz files and Y.npy file of shape {Y.shape}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Stacked Encoding + Stacked Variance Partitioning\n",
    "(The Code automatically performs stacked VPA if vpa=True and saves the data locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now perform stacked encoding analysis on the generated data\n",
    "from net2brain.evaluations.stacked_encoding import Stacked_Encoding\n",
    "\n",
    "# Execute stacked encoding with all parameters\n",
    "results_df = Stacked_Encoding(\n",
    "   feat_path=\"stacked_encoding_sample_data/features\",       # Path to feature files (.npz files)\n",
    "   roi_path=\"stacked_encoding_sample_data\",                 # Path to brain data files\n",
    "   model_name='SampleModel',                                # Name of the model for labeling\n",
    "   n_folds=3,                                               # Number of cross-validation folds\n",
    "   n_components=None,                                       # Number of PCA components (None to skip PCA)\n",
    "   vpa=True,                                                # Whether to perform variance partitioning\n",
    "   save_path='stacked_encoding_sample_data/results'         # Where to save results\n",
    ")\n",
    "\n",
    "results_df = results_df.drop(columns=[\"%R2\", \"LNC\", \"UNC\"])\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Stacked Variance Paritioning with my own data\n",
    "In case you don't want to combine Stacked Encoding with VPA you can call the function with your own data as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to run variance partitioning separately\n",
    "from net2brain.evaluations.stacked_variance_partitioning import Stacked_Variance_Partitioning\n",
    "import numpy as np\n",
    "\n",
    "# In this case we are using the data we generated above!\n",
    "r2s = np.load(\"stacked_encoding_sample_data/results/brain_data_SampleModel_stacked_encoding.npz\", allow_pickle=True)[\"r2s\"]\n",
    "stacked_r2s = np.load(\"stacked_encoding_sample_data/results/brain_data_SampleModel_stacked_encoding.npz\", allow_pickle=True)[\"stacked_r2s\"]\n",
    "\n",
    "# Run variance partitioning\n",
    "vp_results = Stacked_Variance_Partitioning(\n",
    "   r2s=r2s,                               # R² values for individual layers\n",
    "   stacked_r2s=stacked_r2s,               # R² values for stacked model\n",
    "   save_path='sample_data/vp_results'     # Where to save results\n",
    ")\n",
    "\n",
    "print(\"Forward layer assignments per voxel:\", vp_results['vp_sel_layer_forward'])\n",
    "print(\"Backward layer assignments per voxel:\", vp_results['vpr_sel_layer_backward'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "N2B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2143370df03d7e8d8afb3cb32a8181ea228f5a6f13a304f592978240ae0036e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
